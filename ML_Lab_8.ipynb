{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe87sDZSuBoj7ngKC9QVjr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yadukul/ML-Lab/blob/main/ML_Lab_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YADUKUL S\n",
        "CSE2122"
      ],
      "metadata": {
        "id": "o74ecNKVZuY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1. For the data provided below, calculate the prior probability for each class"
      ],
      "metadata": {
        "id": "XYVIHk1GZyUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ryr1egTEtQc",
        "outputId": "0ffd3ec3-2e72-4301-9e79-6c86de7e757d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior Probability P(buys_computer = 'no'): 0.364\n",
            "Prior Probability P(buys_computer = 'yes'): 0.636\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load data from Excel file\n",
        "excel_file = \"lab8 dataset.xlsx\"\n",
        "df = pd.read_excel(excel_file)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded = df.apply(label_encoder.fit_transform)\n",
        "\n",
        "# Splitting the data into features and target\n",
        "X = df_encoded.drop('buys_computer', axis=1)  # Make sure to use lowercase 'buys_computer'\n",
        "y = df_encoded['buys_computer']  # Make sure to use lowercase 'buys_computer'\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using Naive Bayes classifier\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Prior probabilities estimated by the classifier\n",
        "prior_probabilities = np.exp(naive_bayes_classifier.class_log_prior_)\n",
        "\n",
        "# Print the results\n",
        "classes = label_encoder.classes_\n",
        "for i, class_label in enumerate(classes):\n",
        "    print(f'Prior Probability P(buys_computer = \\'{class_label}\\'): {prior_probabilities[i]:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2. Calculate the class conditional densities for various features & classes. Observe if any class\n",
        "conditional density has zero values."
      ],
      "metadata": {
        "id": "IXalom7cZ2-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded = df.apply(label_encoder.fit_transform)\n",
        "\n",
        "# Splitting the data into features and target\n",
        "X = df_encoded.drop('buys_computer', axis=1)\n",
        "y = df_encoded['buys_computer']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using Naive Bayes classifier\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Calculate class conditional densities in log scale\n",
        "log_class_conditional_densities = naive_bayes_classifier.feature_log_prob_\n",
        "\n",
        "# Exponentiate the values to get actual probabilities\n",
        "class_conditional_densities = np.exp(log_class_conditional_densities)\n",
        "\n",
        "# Print the results\n",
        "classes = label_encoder.classes_\n",
        "features = X.columns\n",
        "\n",
        "print(\"Class Conditional Densities:\")\n",
        "for i, class_label in enumerate(classes):\n",
        "    print(f\"\\nClass: {class_label}\")\n",
        "    for j, feature in enumerate(features):\n",
        "        print(f\"Feature: {feature}\")\n",
        "        print(f\"  Class Conditional Density: {class_conditional_densities[i, j]:.3f}\")\n",
        "        if class_conditional_densities[i, j] == 0:\n",
        "            print(f\"  Observation: This class conditional density has a zero value.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXFt2Z5tLswE",
        "outputId": "01d84c3f-7bcd-4fea-c5b7-73e49c335efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Conditional Densities:\n",
            "\n",
            "Class: no\n",
            "Feature: age\n",
            "  Class Conditional Density: 0.412\n",
            "Feature: income\n",
            "  Class Conditional Density: 0.353\n",
            "Feature: student\n",
            "  Class Conditional Density: 0.118\n",
            "Feature: credit_rating\n",
            "  Class Conditional Density: 0.118\n",
            "\n",
            "Class: yes\n",
            "Feature: age\n",
            "  Class Conditional Density: 0.259\n",
            "Feature: income\n",
            "  Class Conditional Density: 0.296\n",
            "Feature: student\n",
            "  Class Conditional Density: 0.222\n",
            "Feature: credit_rating\n",
            "  Class Conditional Density: 0.222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3. Test for independence between the 4 given features."
      ],
      "metadata": {
        "id": "BKKN1RFQZ8kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(index=df['age'], columns=[df['income'], df['student'], df['credit_rating']])\n",
        "\n",
        "# Perform the Chi-squared test of independence\n",
        "chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "# Print the results\n",
        "print(\"Chi-squared Statistic:\", chi2_stat)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Check the significance level\n",
        "alpha = 0.05\n",
        "print(\"\\nTest Result:\")\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is evidence of dependence between the variables.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant evidence of dependence between the variables.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZboOZNHN_tN",
        "outputId": "b03b9c70-cf9b-43ae-da04-4aabce40209d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared Statistic: 12.95\n",
            "P-value: 0.6764100579553458\n",
            "\n",
            "Test Result:\n",
            "Fail to reject the null hypothesis. There is no significant evidence of dependence between the variables.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4. Build a NaÃ¯ve-Bayes (NB) classifier for the above given data. Below code for help.\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(Tr_X,Tr_y)"
      ],
      "metadata": {
        "id": "IYqlkj8MZ_aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded = df.apply(label_encoder.fit_transform)\n",
        "\n",
        "# Splitting the data into features and target\n",
        "X = df_encoded.drop('buys_computer', axis=1)\n",
        "y = df_encoded['buys_computer']\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using Naive Bayes classifier\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = naive_bayes_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjKlOieuOgwS",
        "outputId": "ddcb6d1d-796f-44dd-f6de-432263ec4950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6666666666666666\n",
            "\n",
            "Confusion Matrix:\n",
            " [[0 1]\n",
            " [0 2]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.33      0.50      0.40         3\n",
            "weighted avg       0.44      0.67      0.53         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5. Build a NB classifier for your own project data\n"
      ],
      "metadata": {
        "id": "8pmC1SAZaEu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from scipy.stats import chi2_contingency\n",
        "from itertools import product\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.read_excel('/content/embeddingsdata.xlsx')\n",
        "\n",
        "\n",
        "# Separate features and target\n",
        "features = data.iloc[:, :-1]  # Features\n",
        "target = data.iloc[:, -1]      # Target data\n",
        "\n",
        "# Convert categorical data to numerical values using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in features.columns:\n",
        "    features[col] = label_encoder.fit_transform(features[col])\n",
        "\n",
        "# Convert features to numeric values\n",
        "features = features.astype(float)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Gaussian Naive Bayes classifier\n",
        "gnb_classifier = GaussianNB()\n",
        "gnb_classifier.fit(features_train, target_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = gnb_classifier.predict(features_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = np.sum(predictions == target_test) / len(target_test)\n",
        "print(f'Accuracy: {accuracy:.2%}')"
      ],
      "metadata": {
        "id": "1OSv5UCOSO0a",
        "outputId": "a47194b3-85a7-4dd2-f905-8d20f6783a4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 55.00%\n"
          ]
        }
      ]
    }
  ]
}